{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Preprocessor\n",
    "=================\n",
    "\n",
    "Target creation, data splitting, and preprocessing pipeline.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import Dict, Any, Tuple, Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from ..core.config import PipelineConfig\n",
    "from ..core.exceptions import DataValidationError\n",
    "\n",
    "\n",
    "class TargetCreator:\n",
    "    \"\"\"\n",
    "    Creates target variable using temporal split.\n",
    "    \n",
    "    Prevents data leakage by using time-based cutoff.\n",
    "    \"\"\"\n",
    "    \n",
    "    BAD_STATUSES = ['2', '3', '4', '5']\n",
    "    TEMPORAL_CUTOFF = -6\n",
    "    \n",
    "    def __init__(self, logger: Optional[logging.Logger] = None):\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "    \n",
    "    def create_target(\n",
    "        self,\n",
    "        app_data: pd.DataFrame,\n",
    "        credit_data: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create target variable from credit history.\n",
    "        \n",
    "        Uses temporal split to prevent data leakage.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"ğŸ¯ Creating target variable...\")\n",
    "        \n",
    "        # Split credit data temporally\n",
    "        observed = credit_data[credit_data['MONTHS_BALANCE'] < self.TEMPORAL_CUTOFF]\n",
    "        future = credit_data[credit_data['MONTHS_BALANCE'] >= self.TEMPORAL_CUTOFF]\n",
    "        \n",
    "        self.logger.info(f\"   ğŸ“Š Observed records: {len(observed):,}\")\n",
    "        self.logger.info(f\"   ğŸ“Š Future records: {len(future):,}\")\n",
    "        \n",
    "        # Identify customers with bad credit in future\n",
    "        bad_customers = future[\n",
    "            future['STATUS'].astype(str).isin(self.BAD_STATUSES)\n",
    "        ]['ID'].unique()\n",
    "        \n",
    "        # Filter to customers with both observed and future data\n",
    "        valid_ids = set(observed['ID'].unique()) & set(future['ID'].unique())\n",
    "        self.logger.info(f\"   ğŸ“Š Valid customers: {len(valid_ids):,}\")\n",
    "        \n",
    "        # Create target\n",
    "        app_data = app_data[app_data['ID'].isin(valid_ids)].copy()\n",
    "        app_data['target'] = app_data['ID'].isin(bad_customers).astype(int)\n",
    "        \n",
    "        # Log target distribution\n",
    "        target_dist = app_data['target'].value_counts()\n",
    "        self.logger.info(f\"   ğŸ“Š Target distribution: 0={target_dist.get(0, 0):,}, 1={target_dist.get(1, 0):,}\")\n",
    "        \n",
    "        return app_data\n",
    "\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"\n",
    "    Safe data splitting to prevent leakage.\n",
    "    \n",
    "    Performs stratified splits for train/val/test.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig, logger: Optional[logging.Logger] = None):\n",
    "        self.config = config\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "    \n",
    "    def split(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Split data into train/val/test sets.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with X_train, X_val, X_test, y_train, y_val, y_test\n",
    "        \"\"\"\n",
    "        self.logger.info(\"âœ‚ï¸ Splitting data...\")\n",
    "        \n",
    "        if 'target' not in data.columns:\n",
    "            raise DataValidationError(\"Target column not found\")\n",
    "        \n",
    "        X = data.drop('target', axis=1)\n",
    "        y = data['target']\n",
    "        \n",
    "        # Determine stratification\n",
    "        stratify = y if y.value_counts().min() >= 2 else None\n",
    "        \n",
    "        # First split: train+val vs test\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=self.config.test_size,\n",
    "            random_state=self.config.random_state,\n",
    "            stratify=stratify\n",
    "        )\n",
    "        \n",
    "        # Second split: train vs val\n",
    "        val_size_adjusted = self.config.val_size / (1 - self.config.test_size)\n",
    "        temp_stratify = y_temp if y_temp.value_counts().min() >= 2 else None\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp,\n",
    "            test_size=val_size_adjusted,\n",
    "            random_state=self.config.random_state,\n",
    "            stratify=temp_stratify\n",
    "        )\n",
    "        \n",
    "        # Log split sizes\n",
    "        total = len(data)\n",
    "        self.logger.info(f\"   ğŸ“Š Train: {len(X_train):,} ({len(X_train)/total*100:.1f}%)\")\n",
    "        self.logger.info(f\"   ğŸ“Š Val: {len(X_val):,} ({len(X_val)/total*100:.1f}%)\")\n",
    "        self.logger.info(f\"   ğŸ“Š Test: {len(X_test):,} ({len(X_test)/total*100:.1f}%)\")\n",
    "        \n",
    "        # Create CV folds\n",
    "        cv_folds = self._create_cv_folds(X_train, y_train)\n",
    "        \n",
    "        return {\n",
    "            'X_train': X_train,\n",
    "            'X_val': X_val,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_val': y_val,\n",
    "            'y_test': y_test,\n",
    "            'cv_folds': cv_folds\n",
    "        }\n",
    "    \n",
    "    def _create_cv_folds(\n",
    "        self,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train: pd.Series\n",
    "    ) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Create cross-validation folds.\"\"\"\n",
    "        try:\n",
    "            cv = StratifiedKFold(\n",
    "                n_splits=self.config.cv_folds,\n",
    "                shuffle=True,\n",
    "                random_state=self.config.random_state\n",
    "            )\n",
    "            return list(cv.split(X_train, y_train))\n",
    "        except ValueError:\n",
    "            from sklearn.model_selection import KFold\n",
    "            cv = KFold(\n",
    "                n_splits=self.config.cv_folds,\n",
    "                shuffle=True,\n",
    "                random_state=self.config.random_state\n",
    "            )\n",
    "            return list(cv.split(X_train))\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline.\n",
    "    \n",
    "    Orchestrates target creation, splitting, and feature engineering.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: PipelineConfig, logger: Optional[logging.Logger] = None):\n",
    "        self.config = config\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.target_creator = TargetCreator(logger)\n",
    "        self.data_splitter = DataSplitter(config, logger)\n",
    "    \n",
    "    def preprocess(\n",
    "        self,\n",
    "        app_data: pd.DataFrame,\n",
    "        credit_data: pd.DataFrame,\n",
    "        feature_engineer: 'FeatureEngineer'\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run complete preprocessing pipeline.\n",
    "        \n",
    "        Returns:\n",
    "            Processed splits with features\n",
    "        \"\"\"\n",
    "        self.logger.info(\"\\nğŸ”„ Running preprocessing pipeline...\")\n",
    "        \n",
    "        # Create target\n",
    "        data_with_target = self.target_creator.create_target(app_data, credit_data)\n",
    "        \n",
    "        # Split data\n",
    "        splits = self.data_splitter.split(data_with_target)\n",
    "        \n",
    "        # Fit feature engineer on training data only\n",
    "        feature_engineer.fit(splits['X_train'], splits['y_train'])\n",
    "        \n",
    "        # Transform all splits\n",
    "        splits['X_train'] = feature_engineer.transform(splits['X_train'])\n",
    "        splits['X_val'] = feature_engineer.transform(splits['X_val'])\n",
    "        splits['X_test'] = feature_engineer.transform(splits['X_test'])\n",
    "        \n",
    "        self.logger.info(f\"   âœ… Final features: {len(feature_engineer.final_features)}\")\n",
    "        \n",
    "        return splits\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}