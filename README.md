# Credit Approval ML Pipeline

> **MLOps-Ready Production Architecture** for Credit Card Approval Prediction

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ—ï¸ Architecture Overview

This project implements **MLOps-Ready Production Architecture**, a design pattern optimized for enterprise ML systems. It separates concerns into distinct layers, enabling:

- **Modularity**: Each component is independently testable and replaceable
- **Scalability**: Easy to add new models, features, or data sources
- **Maintainability**: Clear code organization with single responsibility
- **Reproducibility**: YAML configs for experiment tracking
- **Deployability**: Docker support for containerized deployment

### Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ENTRY POINTS                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ main.py  â”‚  â”‚ scripts/     â”‚  â”‚ Docker       â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚ train.py     â”‚  â”‚ Container    â”‚               â”‚
â”‚       â”‚        â”‚ predict.py   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚       â–¼        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      PIPELINE LAYER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  TrainingPipeline       â”‚  â”‚  InferencePipeline      â”‚       â”‚
â”‚  â”‚  - Orchestrates train   â”‚  â”‚  - Batch predictions    â”‚       â”‚
â”‚  â”‚  - Model selection      â”‚  â”‚  - Single predictions   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      BUSINESS LOGIC LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ DataLoad â”‚ â”‚ Feature  â”‚ â”‚ Model    â”‚ â”‚ Model            â”‚    â”‚
â”‚  â”‚ Validate â”‚ â”‚ Engineer â”‚ â”‚ Factory  â”‚ â”‚ Trainer          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      CORE LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ConfigLoader â”‚  â”‚ Logger       â”‚  â”‚ Custom Exceptions    â”‚   â”‚
â”‚  â”‚ (YAML)       â”‚  â”‚ (File+Term)  â”‚  â”‚ (Hierarchy)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      INFRASTRUCTURE                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ configs/ â”‚  â”‚ data/    â”‚  â”‚ docker/  â”‚  â”‚ tests/       â”‚     â”‚
â”‚  â”‚ (YAML)   â”‚  â”‚ (CSV)    â”‚  â”‚ (Deploy) â”‚  â”‚ (pytest)     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
credit-approval/
â”œâ”€â”€ configs/                    # YAML configuration files
â”‚   â”œâ”€â”€ base.yaml              # Project settings, data paths
â”‚   â”œâ”€â”€ training.yaml          # Model hyperparameters
â”‚   â””â”€â”€ deployment.yaml        # Business params, thresholds
â”‚
â”œâ”€â”€ src/                        # Source code package
â”‚   â”œâ”€â”€ __init__.py            # Package exports
â”‚   â”œâ”€â”€ core/                  # Core utilities
â”‚   â”‚   â”œâ”€â”€ config.py          # YAML config loader
â”‚   â”‚   â”œâ”€â”€ logger.py          # Logging system
â”‚   â”‚   â””â”€â”€ exceptions.py      # Custom exceptions
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                  # Data layer
â”‚   â”‚   â”œâ”€â”€ loader.py          # Multi-env data loading
â”‚   â”‚   â””â”€â”€ validator.py       # Data validation
â”‚   â”‚
â”‚   â”œâ”€â”€ features/              # Feature engineering
â”‚   â”‚   â”œâ”€â”€ engineer.py        # Feature creation
â”‚   â”‚   â””â”€â”€ preprocessor.py    # Preprocessing pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Model layer
â”‚   â”‚   â”œâ”€â”€ factory.py         # Model factory (GPU/CPU)
â”‚   â”‚   â””â”€â”€ registry.py        # Model versioning
â”‚   â”‚
â”‚   â”œâ”€â”€ training/              # Training layer
â”‚   â”‚   â”œâ”€â”€ trainer.py         # Model training
â”‚   â”‚   â””â”€â”€ optimizer.py       # Optuna integration
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/            # Evaluation layer
â”‚   â”‚   â”œâ”€â”€ evaluator.py       # Model evaluation
â”‚   â”‚   â””â”€â”€ metrics.py         # Business metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/             # Pipeline orchestration
â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract pipeline
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
â”‚   â”‚   â””â”€â”€ inference_pipeline.py
â”‚   â”‚
â”‚   â””â”€â”€ serving/               # Production serving
â”‚       â””â”€â”€ predictor.py       # API-ready predictor
â”‚
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ docker/                     # Containerization
â”‚   â”œâ”€â”€ Dockerfile             # Multi-stage build
â”‚   â””â”€â”€ docker-compose.yml     # Service definitions
â”‚
â”œâ”€â”€ scripts/                    # CLI scripts
â”‚   â”œâ”€â”€ train.py               # Training CLI
â”‚   â””â”€â”€ predict.py             # Prediction CLI
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original CSV files
â”‚   â””â”€â”€ processed/             # Transformed data
â”‚
â”œâ”€â”€ ml_pipeline_output/         # Pipeline outputs
â”‚   â”œâ”€â”€ models/                # Trained models (.joblib)
â”‚   â”œâ”€â”€ plots/                 # Visualizations
â”‚   â”œâ”€â”€ results/               # Reports (JSON, CSV)
â”‚   â”œâ”€â”€ logs/                  # Execution logs
â”‚   â””â”€â”€ final_model/           # Deployment artifacts
â”‚
â”œâ”€â”€ main.py                     # Main entry point
â”œâ”€â”€ setup.py                    # Package installation
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone repository
git clone https://github.com/example/credit-approval.git
cd credit-approval

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or install as package
pip install -e .
```

### 2. Run Training Pipeline

```bash
# Basic training
python main.py

# With custom parameters
python main.py --trials 100 --cv-folds 10 --no-gpu

# Using CLI script
python scripts/train.py --trials 50
```

### 3. Make Predictions

```bash
# Single prediction
python scripts/predict.py --single '{"DAYS_BIRTH": -10000, "AMT_INCOME_TOTAL": 100000}'

# Batch prediction
python scripts/predict.py --input customers.csv --output predictions.csv
```

---

## ğŸŒ Environment Support

### Google Colab

```python
# 1. Upload project to Google Drive

# 2. In Colab notebook:
from google.colab import drive
drive.mount('/content/drive')

%cd /content/drive/MyDrive/credit-approval

!pip install -r requirements.txt

!python main.py
```

### Kaggle

```python
# Data is auto-detected from /kaggle/input/
!pip install -r requirements.txt
!python main.py
```

### Docker

```bash
# Build and run training
docker-compose -f docker/docker-compose.yml up training

# Run inference service
docker-compose -f docker/docker-compose.yml up inference
```

---

## ğŸ”§ Configuration

All settings are in YAML files under `configs/`:

### base.yaml
```yaml
project:
  name: "credit-approval-ml"
  version: "3.0.0"

model:
  random_state: 42
  cv_folds: 5
  test_size: 0.1
```

### Environment Variables

Override configs with environment variables:
```bash
export ML_OPTUNA_TRIALS=100
export ML_GPU_ENABLED=false
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=src --cov-report=html
```

---

## ğŸ“Š Supported Models

| Model | GPU Support | Auto-Optimization |
|-------|-------------|-------------------|
| XGBoost | âœ… | âœ… |
| LightGBM | âœ… | âœ… |
| CatBoost | âœ… | âœ… |
| RandomForest | âŒ | âœ… |
| GradientBoosting | âŒ | âœ… |
| LogisticRegression | âŒ | âœ… |

---

## ğŸ›ï¸ Design Patterns Used

1. **Factory Pattern**: `ModelFactory` creates models with consistent interface
2. **Pipeline Pattern**: `TrainingPipeline` / `InferencePipeline` orchestrate workflows
3. **Registry Pattern**: `ModelRegistry` manages model versioning
4. **Strategy Pattern**: Different preprocessing strategies per data type
5. **Dependency Injection**: Components receive config/logger via constructor

---

## ğŸ“ˆ Pipeline Flow

```
1. Data Loading     â†’ Load CSV files, detect environment
2. Data Validation  â†’ Check columns, types, quality
3. Target Creation  â†’ Temporal split to prevent leakage
4. Data Splitting   â†’ Stratified train/val/test splits
5. Feature Engineering â†’ Create derived features
6. Hyperparameter Optimization â†’ Optuna-based tuning
7. Model Training   â†’ Train all available models
8. Evaluation       â†’ Test set metrics, cross-validation
9. Model Selection  â†’ Composite scoring, best model
10. Business Analysis â†’ Cost-benefit, ROI calculation
11. Deployment Prep  â†’ Save final model and artifacts
```

---

## ğŸ“¦ Outputs

After running the pipeline, find outputs in `ml_pipeline_output/`:

- `models/` - All trained models with registry
- `plots/` - Confusion matrices, ROC curves, feature importance
- `results/` - Evaluation reports, business case document
- `logs/` - Detailed execution logs
- `final_model/` - Deployment-ready model and feature engineer

---

## ğŸ“„ License

MIT License - see LICENSE file for details.