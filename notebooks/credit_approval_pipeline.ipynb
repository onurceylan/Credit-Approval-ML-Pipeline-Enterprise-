{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Credit Approval ML Pipeline\n",
                "\n",
                "> **Clean Architecture + MLOps-Ready Production Architecture**\n",
                "\n",
                "Bu notebook, kredi onay tahmin modeli i√ßin tam ML pipeline i√ßerir.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìã Table of Contents\n",
                "\n",
                "1. [Environment Setup](#1-environment-setup)\n",
                "2. [Configuration](#2-configuration)\n",
                "3. [Data Loading & Validation](#3-data-loading--validation)\n",
                "4. [Feature Engineering](#4-feature-engineering)\n",
                "5. [Model Training](#5-model-training)\n",
                "6. [Model Evaluation](#6-model-evaluation)\n",
                "7. [Results & Business Analysis](#7-results--business-analysis)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 1.1 Install Dependencies (Colab/Kaggle)\n",
                "# ============================================\n",
                "\n",
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Detect environment\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "IN_KAGGLE = os.path.exists('/kaggle')\n",
                "\n",
                "print(f\"üåê Environment: {'Colab' if IN_COLAB else 'Kaggle' if IN_KAGGLE else 'Local'}\")\n",
                "\n",
                "# Install required packages\n",
                "if IN_COLAB or IN_KAGGLE:\n",
                "    !pip install -q xgboost lightgbm catboost optuna scikit-learn pandas numpy matplotlib seaborn pyyaml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 1.2 Mount Google Drive (Colab only)\n",
                "# ============================================\n",
                "\n",
                "if IN_COLAB:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    \n",
                "    # Change to project directory if exists\n",
                "    project_path = '/content/drive/MyDrive/credit-approval'\n",
                "    if os.path.exists(project_path):\n",
                "        os.chdir(project_path)\n",
                "        print(f\"üìÅ Changed to: {project_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 1.3 Import Libraries\n",
                "# ============================================\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Core\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from datetime import datetime\n",
                "from dataclasses import dataclass, field\n",
                "from typing import Dict, Any, Optional, List, Tuple\n",
                "from pathlib import Path\n",
                "import json\n",
                "import gc\n",
                "import logging\n",
                "\n",
                "# ML\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, confusion_matrix, classification_report\n",
                ")\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Optional GPU libraries\n",
                "try:\n",
                "    import xgboost as xgb\n",
                "    HAS_XGB = True\n",
                "except ImportError:\n",
                "    HAS_XGB = False\n",
                "\n",
                "try:\n",
                "    import lightgbm as lgb\n",
                "    HAS_LGB = True\n",
                "except ImportError:\n",
                "    HAS_LGB = False\n",
                "\n",
                "try:\n",
                "    from catboost import CatBoostClassifier\n",
                "    HAS_CAT = True\n",
                "except ImportError:\n",
                "    HAS_CAT = False\n",
                "\n",
                "try:\n",
                "    import optuna\n",
                "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
                "    HAS_OPTUNA = True\n",
                "except ImportError:\n",
                "    HAS_OPTUNA = False\n",
                "\n",
                "print(\"‚úÖ Libraries imported\")\n",
                "print(f\"   XGBoost: {HAS_XGB}, LightGBM: {HAS_LGB}, CatBoost: {HAS_CAT}, Optuna: {HAS_OPTUNA}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 1.4 Check GPU\n",
                "# ============================================\n",
                "\n",
                "import subprocess\n",
                "\n",
                "def check_gpu():\n",
                "    try:\n",
                "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
                "        if result.returncode == 0:\n",
                "            print(\"‚úÖ GPU Available\")\n",
                "            # Show GPU info\n",
                "            for line in result.stdout.split('\\n'):\n",
                "                if 'NVIDIA' in line or 'MiB' in line:\n",
                "                    print(f\"   {line.strip()}\")\n",
                "            return True\n",
                "    except:\n",
                "        pass\n",
                "    print(\"‚ö†Ô∏è No GPU detected, using CPU\")\n",
                "    return False\n",
                "\n",
                "USE_GPU = check_gpu()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 2.1 Configuration Class\n",
                "# ============================================\n",
                "\n",
                "@dataclass\n",
                "class Config:\n",
                "    \"\"\"Pipeline configuration.\"\"\"\n",
                "    \n",
                "    # Data paths\n",
                "    data_paths: Dict[str, str] = field(default_factory=dict)\n",
                "    \n",
                "    # Model parameters\n",
                "    cv_folds: int = 5\n",
                "    test_size: float = 0.1\n",
                "    val_size: float = 0.2\n",
                "    random_state: int = 42\n",
                "    n_jobs: int = -1\n",
                "    \n",
                "    # Optuna\n",
                "    optuna_trials: int = 30\n",
                "    optuna_timeout: int = 600  # 10 minutes\n",
                "    \n",
                "    # Business parameters\n",
                "    cost_false_positive: float = 5000\n",
                "    cost_false_negative: float = 500\n",
                "    revenue_per_approval: float = 1200\n",
                "    \n",
                "    # Output\n",
                "    output_dir: str = \"ml_pipeline_output\"\n",
                "    \n",
                "    # GPU\n",
                "    use_gpu: bool = True\n",
                "    \n",
                "    def __post_init__(self):\n",
                "        if not self.data_paths:\n",
                "            self.data_paths = self._find_data()\n",
                "        self._create_output_dirs()\n",
                "    \n",
                "    def _find_data(self) -> Dict[str, str]:\n",
                "        \"\"\"Find data files.\"\"\"\n",
                "        paths_to_try = [\n",
                "            # Colab Drive\n",
                "            {'app': '/content/drive/MyDrive/credit-approval/data/raw/application_record.csv',\n",
                "             'credit': '/content/drive/MyDrive/credit-approval/data/raw/credit_record.csv'},\n",
                "            # Colab local\n",
                "            {'app': '/content/application_record.csv', 'credit': '/content/credit_record.csv'},\n",
                "            # Kaggle\n",
                "            {'app': '/kaggle/input/credit-card-approval-prediction/application_record.csv',\n",
                "             'credit': '/kaggle/input/credit-card-approval-prediction/credit_record.csv'},\n",
                "            # Local\n",
                "            {'app': 'data/raw/application_record.csv', 'credit': 'data/raw/credit_record.csv'},\n",
                "            {'app': 'application_record.csv', 'credit': 'credit_record.csv'},\n",
                "        ]\n",
                "        \n",
                "        for paths in paths_to_try:\n",
                "            if Path(paths['app']).exists() and Path(paths['credit']).exists():\n",
                "                print(f\"‚úÖ Data found: {Path(paths['app']).parent}\")\n",
                "                return {'application': paths['app'], 'credit': paths['credit']}\n",
                "        \n",
                "        print(\"‚ö†Ô∏è Data not found, please set config.data_paths manually\")\n",
                "        return {'application': 'application_record.csv', 'credit': 'credit_record.csv'}\n",
                "    \n",
                "    def _create_output_dirs(self):\n",
                "        \"\"\"Create output directories.\"\"\"\n",
                "        for subdir in ['models', 'plots', 'results', 'logs', 'final_model']:\n",
                "            Path(f\"{self.output_dir}/{subdir}\").mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Create config\n",
                "config = Config(use_gpu=USE_GPU)\n",
                "print(f\"\\nüìã Configuration loaded\")\n",
                "print(f\"   Random state: {config.random_state}\")\n",
                "print(f\"   CV folds: {config.cv_folds}\")\n",
                "print(f\"   GPU: {config.use_gpu}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Data Loading & Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 3.1 Load Data\n",
                "# ============================================\n",
                "\n",
                "print(\"üì• Loading data...\")\n",
                "\n",
                "app_data = pd.read_csv(config.data_paths['application'])\n",
                "credit_data = pd.read_csv(config.data_paths['credit'])\n",
                "\n",
                "print(f\"\\nüìä Application data: {app_data.shape}\")\n",
                "print(f\"üìä Credit data: {credit_data.shape}\")\n",
                "\n",
                "# Show sample\n",
                "display(app_data.head(3))\n",
                "display(credit_data.head(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 3.2 Data Validation\n",
                "# ============================================\n",
                "\n",
                "print(\"üîç Validating data...\")\n",
                "\n",
                "# Check required columns\n",
                "assert 'ID' in app_data.columns, \"Missing ID in application data\"\n",
                "assert 'ID' in credit_data.columns, \"Missing ID in credit data\"\n",
                "assert 'MONTHS_BALANCE' in credit_data.columns, \"Missing MONTHS_BALANCE\"\n",
                "assert 'STATUS' in credit_data.columns, \"Missing STATUS\"\n",
                "\n",
                "# ID overlap\n",
                "app_ids = set(app_data['ID'].unique())\n",
                "credit_ids = set(credit_data['ID'].unique())\n",
                "common_ids = app_ids & credit_ids\n",
                "\n",
                "print(f\"\\n‚úÖ Validation passed\")\n",
                "print(f\"   Application IDs: {len(app_ids):,}\")\n",
                "print(f\"   Credit IDs: {len(credit_ids):,}\")\n",
                "print(f\"   Common IDs: {len(common_ids):,} ({len(common_ids)/len(app_ids)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 3.3 Create Target Variable (Temporal Split)\n",
                "# ============================================\n",
                "\n",
                "print(\"üéØ Creating target variable...\")\n",
                "\n",
                "BAD_STATUSES = ['2', '3', '4', '5']  # 60+ days overdue\n",
                "TEMPORAL_CUTOFF = -6\n",
                "\n",
                "# Split credit data temporally\n",
                "observed = credit_data[credit_data['MONTHS_BALANCE'] < TEMPORAL_CUTOFF]\n",
                "future = credit_data[credit_data['MONTHS_BALANCE'] >= TEMPORAL_CUTOFF]\n",
                "\n",
                "print(f\"   Observed records: {len(observed):,}\")\n",
                "print(f\"   Future records: {len(future):,}\")\n",
                "\n",
                "# Find customers with bad credit in future\n",
                "bad_customers = future[future['STATUS'].astype(str).isin(BAD_STATUSES)]['ID'].unique()\n",
                "\n",
                "# Filter to customers with both observed and future\n",
                "valid_ids = set(observed['ID'].unique()) & set(future['ID'].unique())\n",
                "print(f\"   Valid customers: {len(valid_ids):,}\")\n",
                "\n",
                "# Create target\n",
                "data = app_data[app_data['ID'].isin(valid_ids)].copy()\n",
                "data['target'] = data['ID'].isin(bad_customers).astype(int)\n",
                "\n",
                "print(f\"\\nüìä Target distribution:\")\n",
                "print(data['target'].value_counts())\n",
                "print(f\"   Bad rate: {data['target'].mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 4.1 Data Splitting\n",
                "# ============================================\n",
                "\n",
                "print(\"‚úÇÔ∏è Splitting data...\")\n",
                "\n",
                "X = data.drop('target', axis=1)\n",
                "y = data['target']\n",
                "\n",
                "# First split: train+val vs test\n",
                "X_temp, X_test, y_temp, y_test = train_test_split(\n",
                "    X, y, test_size=config.test_size, \n",
                "    random_state=config.random_state, stratify=y\n",
                ")\n",
                "\n",
                "# Second split: train vs val\n",
                "val_size_adj = config.val_size / (1 - config.test_size)\n",
                "X_train, X_val, y_train, y_val = train_test_split(\n",
                "    X_temp, y_temp, test_size=val_size_adj,\n",
                "    random_state=config.random_state, stratify=y_temp\n",
                ")\n",
                "\n",
                "print(f\"\\nüìä Split sizes:\")\n",
                "print(f\"   Train: {len(X_train):,} ({len(X_train)/len(data)*100:.1f}%)\")\n",
                "print(f\"   Val: {len(X_val):,} ({len(X_val)/len(data)*100:.1f}%)\")\n",
                "print(f\"   Test: {len(X_test):,} ({len(X_test)/len(data)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 4.2 Feature Engineering\n",
                "# ============================================\n",
                "\n",
                "class FeatureEngineer:\n",
                "    \"\"\"Feature engineering with fit-transform pattern.\"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.scalers = {}\n",
                "        self.encoders = {}\n",
                "        self.is_fitted = False\n",
                "        self.feature_names = []\n",
                "    \n",
                "    def fit(self, X: pd.DataFrame) -> 'FeatureEngineer':\n",
                "        \"\"\"Fit on training data.\"\"\"\n",
                "        X_feat = self._create_features(X.copy())\n",
                "        \n",
                "        # Fit scalers for numeric\n",
                "        numeric_cols = X_feat.select_dtypes(include=[np.number]).columns.tolist()\n",
                "        for col in numeric_cols:\n",
                "            scaler = StandardScaler()\n",
                "            valid = X_feat[col].dropna()\n",
                "            if len(valid) > 0:\n",
                "                scaler.fit(valid.values.reshape(-1, 1))\n",
                "                self.scalers[col] = scaler\n",
                "        \n",
                "        # Fit encoders for categorical\n",
                "        cat_cols = X_feat.select_dtypes(include=['object', 'category']).columns.tolist()\n",
                "        for col in cat_cols:\n",
                "            encoder = LabelEncoder()\n",
                "            valid = X_feat[col].dropna().astype(str)\n",
                "            if len(valid) > 0:\n",
                "                encoder.fit(valid)\n",
                "                self.encoders[col] = encoder\n",
                "        \n",
                "        self.feature_names = numeric_cols + cat_cols\n",
                "        self.is_fitted = True\n",
                "        return self\n",
                "    \n",
                "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Transform using fitted parameters.\"\"\"\n",
                "        X_feat = self._create_features(X.copy())\n",
                "        \n",
                "        # Scale numeric\n",
                "        for col, scaler in self.scalers.items():\n",
                "            if col in X_feat.columns:\n",
                "                valid_idx = X_feat[col].notna()\n",
                "                if valid_idx.any():\n",
                "                    X_feat.loc[valid_idx, col] = scaler.transform(\n",
                "                        X_feat.loc[valid_idx, col].values.reshape(-1, 1)\n",
                "                    ).flatten()\n",
                "        \n",
                "        # Encode categorical\n",
                "        for col, encoder in self.encoders.items():\n",
                "            if col in X_feat.columns:\n",
                "                X_feat[col] = X_feat[col].fillna('Unknown').astype(str)\n",
                "                X_feat[col] = X_feat[col].apply(\n",
                "                    lambda x: encoder.transform([x])[0] if x in encoder.classes_ else -1\n",
                "                )\n",
                "        \n",
                "        return X_feat.fillna(0)\n",
                "    \n",
                "    def fit_transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Fit and transform.\"\"\"\n",
                "        return self.fit(X).transform(X)\n",
                "    \n",
                "    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
                "        \"\"\"Create derived features.\"\"\"\n",
                "        # Age\n",
                "        if 'DAYS_BIRTH' in df.columns:\n",
                "            df['AGE_YEARS'] = (-df['DAYS_BIRTH'] / 365).astype(int)\n",
                "        \n",
                "        # Employment\n",
                "        if 'DAYS_EMPLOYED' in df.columns:\n",
                "            df['EMPLOYED_YEARS'] = df['DAYS_EMPLOYED'].apply(\n",
                "                lambda x: 0 if x > 0 else int(-x / 365)\n",
                "            )\n",
                "            df['IS_EMPLOYED'] = (df['DAYS_EMPLOYED'] < 0).astype(int)\n",
                "        \n",
                "        # Income\n",
                "        if 'AMT_INCOME_TOTAL' in df.columns:\n",
                "            df['INCOME_LOG'] = np.log1p(df['AMT_INCOME_TOTAL'])\n",
                "        \n",
                "        # Family\n",
                "        if 'CNT_CHILDREN' in df.columns:\n",
                "            df['HAS_CHILDREN'] = (df['CNT_CHILDREN'] > 0).astype(int)\n",
                "        \n",
                "        # Income per person\n",
                "        if 'AMT_INCOME_TOTAL' in df.columns and 'CNT_FAM_MEMBERS' in df.columns:\n",
                "            fam = df['CNT_FAM_MEMBERS'].replace(0, 1)\n",
                "            df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / fam\n",
                "        \n",
                "        return df\n",
                "\n",
                "# Apply feature engineering\n",
                "print(\"üî¨ Engineering features...\")\n",
                "\n",
                "fe = FeatureEngineer()\n",
                "X_train_fe = fe.fit_transform(X_train)\n",
                "X_val_fe = fe.transform(X_val)\n",
                "X_test_fe = fe.transform(X_test)\n",
                "\n",
                "print(f\"\\n‚úÖ Feature engineering complete\")\n",
                "print(f\"   Features: {len(fe.feature_names)}\")\n",
                "print(f\"   Numeric scalers: {len(fe.scalers)}\")\n",
                "print(f\"   Categorical encoders: {len(fe.encoders)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Model Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 5.1 Model Factory\n",
                "# ============================================\n",
                "\n",
                "def create_models(use_gpu: bool = False) -> Dict[str, Any]:\n",
                "    \"\"\"Create all available models.\"\"\"\n",
                "    models = {\n",
                "        'LogisticRegression': LogisticRegression(\n",
                "            max_iter=1000, random_state=config.random_state, n_jobs=config.n_jobs\n",
                "        ),\n",
                "        'RandomForest': RandomForestClassifier(\n",
                "            n_estimators=100, max_depth=10,\n",
                "            random_state=config.random_state, n_jobs=config.n_jobs\n",
                "        ),\n",
                "        'GradientBoosting': GradientBoostingClassifier(\n",
                "            n_estimators=100, max_depth=5, learning_rate=0.1,\n",
                "            random_state=config.random_state\n",
                "        ),\n",
                "    }\n",
                "    \n",
                "    if HAS_XGB:\n",
                "        xgb_params = {\n",
                "            'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1,\n",
                "            'random_state': config.random_state, 'n_jobs': config.n_jobs,\n",
                "            'eval_metric': 'logloss'\n",
                "        }\n",
                "        if use_gpu:\n",
                "            xgb_params['tree_method'] = 'gpu_hist'\n",
                "        models['XGBoost'] = xgb.XGBClassifier(**xgb_params)\n",
                "    \n",
                "    if HAS_LGB:\n",
                "        lgb_params = {\n",
                "            'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1,\n",
                "            'random_state': config.random_state, 'n_jobs': config.n_jobs, 'verbose': -1\n",
                "        }\n",
                "        if use_gpu:\n",
                "            lgb_params['device'] = 'gpu'\n",
                "        models['LightGBM'] = lgb.LGBMClassifier(**lgb_params)\n",
                "    \n",
                "    if HAS_CAT:\n",
                "        cat_params = {\n",
                "            'iterations': 100, 'depth': 6, 'learning_rate': 0.1,\n",
                "            'random_seed': config.random_state, 'verbose': False\n",
                "        }\n",
                "        if use_gpu:\n",
                "            cat_params['task_type'] = 'GPU'\n",
                "        models['CatBoost'] = CatBoostClassifier(**cat_params)\n",
                "    \n",
                "    return models\n",
                "\n",
                "models = create_models(config.use_gpu)\n",
                "print(f\"üì¶ Available models: {list(models.keys())}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 5.2 Train All Models\n",
                "# ============================================\n",
                "\n",
                "print(\"üèãÔ∏è Training models...\\n\")\n",
                "\n",
                "results = {}\n",
                "\n",
                "for name, model in models.items():\n",
                "    print(f\"   Training {name}...\", end=\" \")\n",
                "    start = datetime.now()\n",
                "    \n",
                "    try:\n",
                "        # Train\n",
                "        model.fit(X_train_fe, y_train)\n",
                "        \n",
                "        # Predict\n",
                "        y_pred = model.predict(X_val_fe)\n",
                "        y_proba = model.predict_proba(X_val_fe) if hasattr(model, 'predict_proba') else None\n",
                "        \n",
                "        # Metrics\n",
                "        val_acc = accuracy_score(y_val, y_pred)\n",
                "        val_auc = roc_auc_score(y_val, y_proba, multi_class='ovr') if y_proba is not None else 0\n",
                "        val_f1 = f1_score(y_val, y_pred, average='weighted')\n",
                "        \n",
                "        # CV\n",
                "        cv_scores = cross_val_score(model, X_train_fe, y_train, cv=config.cv_folds, scoring='roc_auc_ovr')\n",
                "        \n",
                "        duration = (datetime.now() - start).total_seconds()\n",
                "        \n",
                "        results[name] = {\n",
                "            'model': model,\n",
                "            'val_accuracy': val_acc,\n",
                "            'val_auc': val_auc,\n",
                "            'val_f1': val_f1,\n",
                "            'cv_mean': cv_scores.mean(),\n",
                "            'cv_std': cv_scores.std(),\n",
                "            'duration': duration,\n",
                "            'success': True\n",
                "        }\n",
                "        \n",
                "        print(f\"‚úÖ Acc={val_acc:.4f}, AUC={val_auc:.4f}, CV={cv_scores.mean():.4f}¬±{cv_scores.std():.4f} ({duration:.1f}s)\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Failed: {str(e)[:50]}\")\n",
                "        results[name] = {'success': False, 'error': str(e)}\n",
                "\n",
                "print(f\"\\n‚úÖ Training complete: {sum(r.get('success', False) for r in results.values())}/{len(models)} models\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 6.1 Test Set Evaluation\n",
                "# ============================================\n",
                "\n",
                "print(\"üìä Evaluating on test set...\\n\")\n",
                "\n",
                "test_results = {}\n",
                "\n",
                "for name, result in results.items():\n",
                "    if not result.get('success'):\n",
                "        continue\n",
                "    \n",
                "    model = result['model']\n",
                "    \n",
                "    y_pred = model.predict(X_test_fe)\n",
                "    y_proba = model.predict_proba(X_test_fe) if hasattr(model, 'predict_proba') else None\n",
                "    \n",
                "    test_acc = accuracy_score(y_test, y_pred)\n",
                "    test_auc = roc_auc_score(y_test, y_proba, multi_class='ovr') if y_proba is not None else 0\n",
                "    test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
                "    \n",
                "    test_results[name] = {\n",
                "        'accuracy': test_acc,\n",
                "        'auc': test_auc,\n",
                "        'f1': test_f1,\n",
                "        'predictions': y_pred,\n",
                "        'probabilities': y_proba\n",
                "    }\n",
                "    \n",
                "    print(f\"   {name}: Accuracy={test_acc:.4f}, AUC={test_auc:.4f}, F1={test_f1:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 6.2 Select Best Model\n",
                "# ============================================\n",
                "\n",
                "print(\"\\nüèÜ Selecting best model...\")\n",
                "\n",
                "# Composite score\n",
                "model_scores = {}\n",
                "for name, test_res in test_results.items():\n",
                "    train_res = results[name]\n",
                "    \n",
                "    test_auc = test_res['auc']\n",
                "    cv_mean = train_res['cv_mean']\n",
                "    cv_std = train_res['cv_std']\n",
                "    \n",
                "    stability = 1 / (1 + cv_std)\n",
                "    composite = 0.5 * test_auc + 0.3 * cv_mean + 0.2 * stability\n",
                "    \n",
                "    model_scores[name] = composite\n",
                "\n",
                "best_model_name = max(model_scores, key=model_scores.get)\n",
                "best_model = results[best_model_name]['model']\n",
                "\n",
                "print(f\"\\nü•á Best Model: {best_model_name}\")\n",
                "print(f\"   Composite Score: {model_scores[best_model_name]:.4f}\")\n",
                "print(f\"   Test AUC: {test_results[best_model_name]['auc']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 6.3 Visualizations\n",
                "# ============================================\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Model comparison\n",
                "ax1 = axes[0]\n",
                "model_names = list(test_results.keys())\n",
                "aucs = [test_results[n]['auc'] for n in model_names]\n",
                "colors = ['#2ecc71' if n == best_model_name else '#3498db' for n in model_names]\n",
                "\n",
                "bars = ax1.barh(model_names, aucs, color=colors)\n",
                "ax1.set_xlabel('Test AUC')\n",
                "ax1.set_title('Model Comparison')\n",
                "ax1.set_xlim(0, 1)\n",
                "\n",
                "for bar, auc in zip(bars, aucs):\n",
                "    ax1.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, \n",
                "             f'{auc:.4f}', va='center')\n",
                "\n",
                "# Confusion matrix for best model\n",
                "ax2 = axes[1]\n",
                "cm = confusion_matrix(y_test, test_results[best_model_name]['predictions'])\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2)\n",
                "ax2.set_xlabel('Predicted')\n",
                "ax2.set_ylabel('Actual')\n",
                "ax2.set_title(f'Confusion Matrix - {best_model_name}')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f\"{config.output_dir}/plots/model_comparison.png\", dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Results & Business Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 7.1 Business Impact Analysis\n",
                "# ============================================\n",
                "\n",
                "print(\"üí∞ Business Impact Analysis\\n\")\n",
                "\n",
                "y_pred_best = test_results[best_model_name]['predictions']\n",
                "\n",
                "# Confusion matrix elements\n",
                "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_best).ravel()\n",
                "\n",
                "# Costs\n",
                "cost_fp_total = fp * config.cost_false_negative  # Rejected good customers\n",
                "cost_fn_total = fn * config.cost_false_positive  # Approved bad customers\n",
                "revenue = tn * config.revenue_per_approval\n",
                "\n",
                "total_cost = cost_fp_total + cost_fn_total\n",
                "net_profit = revenue - total_cost\n",
                "roi = (net_profit / total_cost * 100) if total_cost > 0 else 0\n",
                "\n",
                "print(f\"üìä Confusion Matrix:\")\n",
                "print(f\"   True Positives: {tp:,} (correctly identified bad)\")\n",
                "print(f\"   True Negatives: {tn:,} (correctly identified good)\")\n",
                "print(f\"   False Positives: {fp:,} (rejected good customers)\")\n",
                "print(f\"   False Negatives: {fn:,} (approved bad customers)\")\n",
                "\n",
                "print(f\"\\nüíµ Financial Impact:\")\n",
                "print(f\"   Cost of rejecting good: ${cost_fp_total:,.0f}\")\n",
                "print(f\"   Cost of approving bad: ${cost_fn_total:,.0f}\")\n",
                "print(f\"   Revenue from approvals: ${revenue:,.0f}\")\n",
                "print(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
                "print(f\"   Net Profit: ${net_profit:,.0f}\")\n",
                "print(f\"   ROI: {roi:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 7.2 Save Results\n",
                "# ============================================\n",
                "\n",
                "import joblib\n",
                "\n",
                "print(\"üíæ Saving results...\")\n",
                "\n",
                "# Save best model\n",
                "model_path = f\"{config.output_dir}/final_model/model.joblib\"\n",
                "joblib.dump(best_model, model_path)\n",
                "print(f\"   ‚úÖ Model saved: {model_path}\")\n",
                "\n",
                "# Save feature engineer\n",
                "fe_path = f\"{config.output_dir}/final_model/feature_engineer.joblib\"\n",
                "joblib.dump(fe, fe_path)\n",
                "print(f\"   ‚úÖ Feature engineer saved: {fe_path}\")\n",
                "\n",
                "# Save results summary\n",
                "summary = {\n",
                "    'best_model': best_model_name,\n",
                "    'test_accuracy': test_results[best_model_name]['accuracy'],\n",
                "    'test_auc': test_results[best_model_name]['auc'],\n",
                "    'test_f1': test_results[best_model_name]['f1'],\n",
                "    'net_profit': net_profit,\n",
                "    'roi': roi,\n",
                "    'timestamp': datetime.now().isoformat()\n",
                "}\n",
                "\n",
                "with open(f\"{config.output_dir}/results/summary.json\", 'w') as f:\n",
                "    json.dump(summary, f, indent=2)\n",
                "\n",
                "print(f\"   ‚úÖ Summary saved\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# 7.3 Final Summary\n",
                "# ============================================\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üéâ PIPELINE COMPLETE\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
                "print(f\"\\nüìä Test Metrics:\")\n",
                "print(f\"   Accuracy: {test_results[best_model_name]['accuracy']:.4f}\")\n",
                "print(f\"   AUC: {test_results[best_model_name]['auc']:.4f}\")\n",
                "print(f\"   F1 Score: {test_results[best_model_name]['f1']:.4f}\")\n",
                "print(f\"\\nüí∞ Business Impact:\")\n",
                "print(f\"   Net Profit: ${net_profit:,.0f}\")\n",
                "print(f\"   ROI: {roi:.1f}%\")\n",
                "print(f\"\\nüìÅ Outputs: {config.output_dir}/\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìù How to Make Predictions\n",
                "\n",
                "```python\n",
                "import joblib\n",
                "\n",
                "# Load model and feature engineer\n",
                "model = joblib.load('ml_pipeline_output/final_model/model.joblib')\n",
                "fe = joblib.load('ml_pipeline_output/final_model/feature_engineer.joblib')\n",
                "\n",
                "# Prepare new data\n",
                "new_customer = pd.DataFrame([{\n",
                "    'ID': 999,\n",
                "    'DAYS_BIRTH': -10000,\n",
                "    'DAYS_EMPLOYED': -2000,\n",
                "    'AMT_INCOME_TOTAL': 150000,\n",
                "    'CNT_CHILDREN': 1,\n",
                "    'CNT_FAM_MEMBERS': 3,\n",
                "    # ... other features\n",
                "}])\n",
                "\n",
                "# Transform and predict\n",
                "X_new = fe.transform(new_customer)\n",
                "prediction = model.predict(X_new)[0]\n",
                "probability = model.predict_proba(X_new)[0]\n",
                "\n",
                "print(f\"Prediction: {'Bad Credit' if prediction == 1 else 'Good Credit'}\")\n",
                "print(f\"Confidence: {max(probability)*100:.1f}%\")\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}